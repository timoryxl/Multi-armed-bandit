{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Multi Armed Bandit\n",
    "===="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We formulate a simple bandit scheme involving 2 Machines and a Bernoulli Reward (0 or 1). Each Machine has a latent parameter governing its reward. There are a few possible goals:\n",
    "\n",
    "1. Maximize Total Expected Rewards over N Trials\n",
    "2. Find the \"Best\" Machine in as few trials as possible\n",
    "3. Minimize \"Regret\" = Actual Reward - Reward of Best Action over N Trails\n",
    "\n",
    "We designate the following:\n",
    "\n",
    "$$R_1 = \\text{Reward from Machine 1} \\sim \\text{Bernoulli}(\\theta_1)$$\n",
    "$$R_2 = \\text{Reward from Machine 2} \\sim \\text{Bernoulli}(\\theta_2)$$\n",
    "\n",
    "$$\\theta_1 \\sim \\text{Beta}(\\alpha_1, \\beta_1)$$\n",
    "$$\\theta_2 \\sim \\text{Beta}(\\alpha_2, \\beta_2)$$\n",
    "\n",
    "In the beginning, we have no prior knowledge about either Machine, or more specifically, about the latent parameter governing each Machine. Therefore, we initially set $\\alpha_1, \\alpha_2, \\beta_1, \\beta_2 = 1$\n",
    "\n",
    "Given our goals above, the main question becomes: **How do we choose which Machine to play in each Iteration?** We will refer to this question as our utility or acquisition function $U(\\theta | X) = U(\\alpha_1, \\beta_1, \\alpha_2, \\beta_2 | X)$. The idea of this function is to weigh both exploitation of Machines we know give out a high reward, and exploration of other Machines that could possibly be better."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we begin playing and gathering information, we continuously update our parameters of interest based on the outcome. Specifically:\n",
    "\n",
    "1. $U(\\alpha_1, \\beta_1, \\alpha_2, \\beta_2) = j$ \n",
    "    * ( We choose Machine j )\n",
    "2. $R_j = i$  \n",
    "    * ( We play Machine j, and get Reward i )\n",
    "3. If $R_j = 1$:\n",
    "    $\\alpha_j = \\alpha_j + 1$  \n",
    "4. If $R_j = 0$:\n",
    "    $\\beta_j = \\beta_j + 1$  \n",
    "\n",
    "The idea is to update our prior \"belief\" on the success of the individual Machines based on our empirical rewards. $\\alpha$ represents \"success\", while $\\beta$ represents \"failure\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we discuss how to construct our Acquisition Function $U(\\theta|X)$ which will help us decide which Machine to play at each iteration, we see two interesting points:\n",
    "\n",
    "At time T = 1, we have no prior belief concerning any Machine. Thus, it will not matter which Machine we pick the first time around, though it will influence all subsequent choices.\n",
    "\n",
    "At time T = N, we are at our final trial, and thus are only concerned for the Reward on this trial. As such, we will opt for a **Greedy** approach and pick the Machine with the highest Expected Reward - max($\\frac{\\alpha_1}{\\alpha_1 + \\beta_1}, \\frac{\\alpha_2}{\\alpha_2 + \\beta_2}$)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For times T = 2,...,N-1, we must choose the Machine based on the Expected Sum of Future Rewards, based on our framework above: $\\mathbb{E}(\\displaystyle\\sum_{i=1}^{n} R_i)$\n",
    "\n",
    "At time T = t, $\\mathbb{E}(\\displaystyle\\sum_{i=t}^{n} R_i|M_{1:t-1}, R_{1:t-1})$ = $\\mathbb{E}(\\displaystyle\\sum_{i=t+1}^{n} R_i|\\theta)$ + $\\mathbb{E}(R_t|\\theta)$  \n",
    "$M_{1:t}$ = Machines Chosen from times 1 to t  \n",
    "$R_{1:t}$ = Rewards Given from times 1 to t\n",
    "\n",
    "Given we perform N Trials, we construct our Algorithm in a Backwards Fashion:\n",
    "\n",
    "1. For T = N:\n",
    "    * For each node, we choose the **Greedy** option, that is, the one with the maximum expected return.\n",
    "\n",
    "2. For T = N-1\n",
    "    * Given that we know the most optimal choice for the last Trial, we select the Machine on this trial that will give us the maximum Expected **sum** of Rewards\n",
    "    * $\\mathbb{E}(R_{N-1} + R_{N})$, and we know $R_N$ from the previous iteration\n",
    "    \n",
    "3. For T = N-2,...,2:\n",
    "    * We follow the similar intuition as above, choosing the most optimal choice for the maximum Expected sum of rewards, given the optimal choice for all subseqent trials already calculated\n",
    "    * $\\mathbb{E}(\\displaystyle\\sum_{i=T}^{n} R_i)$ = $\\mathbb{E}(\\displaystyle\\sum_{i=t+1}^{n} R_i)$ + $\\mathbb{E}(R_t)$\n",
    "    \n",
    "4. For T = 1:\n",
    "    * From our above note, the first iteration does not matter, as we have no prior knowledge. We select any Machine at random.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn.gaussian_process import GaussianProcess\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.optimize import minimize_scalar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1 :  1\n",
      "Trial 2 :  4\n",
      "Trial 3 :  10\n",
      "Trial 4 :  20\n",
      "Trial 5 :  35\n",
      "Trial 6 :  56\n",
      "Trial 7 :  84\n",
      "Trial 8 :  120\n",
      "Trial 9 :  165\n",
      "Trial 10 :  220\n"
     ]
    }
   ],
   "source": [
    "#Code to Generate Number of Nodes at Trial n#\n",
    "def f(a, b, c, d, n):\n",
    "    if n == 1:\n",
    "        return pd.DataFrame(np.array([a,b,c,d])).T\n",
    "    A = [a+1, b, c, d]\n",
    "    B = [a, b+1, c, d]\n",
    "    C = [a, b, c+1, d]\n",
    "    D = [a, b, c, d+1]\n",
    "    Nodes = pd.DataFrame(np.array([A, B, C, D]))\n",
    "    for j in range(2,n):\n",
    "        X = Nodes.shape[0]\n",
    "        Nodes2 = pd.DataFrame()\n",
    "        for i in range(X):\n",
    "            A = Nodes.ix[i,:] + np.array([1,0,0,0])\n",
    "            B = Nodes.ix[i,:] + np.array([0,1,0,0])\n",
    "            C = Nodes.ix[i,:] + np.array([0,0,1,0])\n",
    "            D = Nodes.ix[i,:] + np.array([0,0,0,1]) \n",
    "            Nodes2 = pd.concat([Nodes2, pd.DataFrame(np.array([A, B, C, D]))])\n",
    "        Nodes = pd.DataFrame(pd.DataFrame.drop_duplicates(Nodes2)).reset_index(drop = True)\n",
    "    return Nodes\n",
    "    \n",
    "def num_nodes(n):    \n",
    "    for i in range(n):\n",
    "        print(\"Trial\",i+1,\": \", f(1,1,1,1,i+1).shape[0])\n",
    "            \n",
    "num_nodes(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def minimize_func(p, E1, E2, E3, E4):\n",
    "    return(-(p*(1 + E1) + p*(0 + E2) + (1-p)*(1 + E3) + (1-p)*(0 + E4)))\n",
    "\n",
    "#Returns Previous Nodes, Finds best choice of machine based on future rewards\n",
    "def Previous_Nodes_Func(a1, b1, a2, b2, N, Final_Nodes):\n",
    "    Previous_Nodes = f(a1,b1,a2,b2,N)\n",
    "    Previous_Nodes.insert(4, 4, 0)\n",
    "    Previous_Nodes.insert(5, 5, 0)\n",
    "    for j in range(Previous_Nodes.shape[0]):\n",
    "        Node = Previous_Nodes.ix[j,0:3]\n",
    "        A = Node + np.array([1,0,0,0])\n",
    "        B = Node + np.array([0,1,0,0])\n",
    "        C = Node + np.array([0,0,1,0])\n",
    "        D = Node + np.array([0,0,0,1])\n",
    "            \n",
    "        E1 = Final_Nodes.values[np.alltrue(Final_Nodes.ix[:,0:3] == A, axis = 1),4]\n",
    "        E2 = Final_Nodes.values[np.alltrue(Final_Nodes.ix[:,0:3] == B, axis = 1),4]\n",
    "        E3 = Final_Nodes.values[np.alltrue(Final_Nodes.ix[:,0:3] == C, axis = 1),4]\n",
    "        E4 = Final_Nodes.values[np.alltrue(Final_Nodes.ix[:,0:3] == D, axis = 1),4]\n",
    "            \n",
    "        choice = np.round(minimize_scalar(minimize_func, method = 'bounded', bounds = [0,1], args = (E1, E2, E3, E4)).x)\n",
    "        Previous_Nodes.ix[j,4] = -minimize_func(choice, E1, E2, E3, E4)\n",
    "        Previous_Nodes.ix[j,5] = choice\n",
    "        \n",
    "    return(Previous_Nodes)\n",
    "\n",
    "#Input:\n",
    "#a1,b1,a2,b2 - Prior Parameters of Machine at CURRENT TRIAL\n",
    "#N - Number of Trials Remaining\n",
    "#\n",
    "#Output:\n",
    "#Choice of Machine at Current Iteration & Expected Sum of Rewards\n",
    "def Bernoulli_Bandit(a1, b1, a2, b2, N):   \n",
    "    \n",
    "    #Create Data Frame of Final Nodes\n",
    "    Final_Nodes = f(a1,b1,a2,b2,N)\n",
    "    \n",
    "    #Create Empty Column to Hold Expected#\n",
    "    Final_Nodes.insert(4, 4, 0)\n",
    "    \n",
    "    #Add Column of Final Expected Result\n",
    "    for i in range(Final_Nodes.shape[0]):\n",
    "        E_1 = Final_Nodes.ix[i,0]/(Final_Nodes.ix[i,0]+Final_Nodes.ix[i,1])\n",
    "        E_2 = Final_Nodes.ix[i,2]/(Final_Nodes.ix[i,2]+Final_Nodes.ix[i,3])\n",
    "        Final_Nodes.ix[i,4] = max(E_1, E_2)\n",
    "\n",
    "    Previous_Node = Final_Nodes\n",
    "    \n",
    "    for j in range(1,N)[::-1]:\n",
    "        Previous_Node = Previous_Nodes_Func(a1, b1, a2, b2, j, Previous_Node)\n",
    "    \n",
    "    return(Previous_Node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2.166667</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2.416667</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2.100000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0  1  2  3         4  5\n",
       "0  3  2  1  1  2.333333  1\n",
       "1  2  3  1  1  2.166667  1\n",
       "2  2  2  2  1  2.416667  1\n",
       "3  2  2  1  2  2.100000  1"
      ]
     },
     "execution_count": 324,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Previous_Nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXMAAAEACAYAAABBDJb9AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nOMAwJyKKA/8fDooNvg2kkXoAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f2d41fa47f0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "##Gaussian Process Code - Unfinished##\n",
    "\n",
    "# Observations\n",
    "y = np.array([1,6])\n",
    "X = np.atleast_2d([2,5]).T\n",
    "\n",
    "# Mesh the input space for evaluations of the real function, the prediction and\n",
    "# its MSE\n",
    "x = np.atleast_2d(np.linspace(0, 10, 1000)).T\n",
    "\n",
    "# Instanciate a Gaussian Process model\n",
    "gp = GaussianProcess(corr='cubic', theta0=1e-2, thetaL=1e-4, thetaU=1e-1,\n",
    "                     random_start=100)\n",
    "\n",
    "# Fit to data using Maximum Likelihood Estimation of the parameters\n",
    "gp.fit(X, y)\n",
    "\n",
    "# Make the prediction on the meshed x-axis (ask for MSE as well)\n",
    "y_pred, MSE = gp.predict(x, eval_MSE=True)\n",
    "sigma = np.sqrt(MSE)\n",
    "\n",
    "#plt.plot(x, f(x), 'r:', label=u'$f(x) = x\\,\\sin(x)$')\n",
    "plt.plot(X, y, 'r.', markersize=10, label=u'Observations')\n",
    "plt.plot(x, y_pred, 'b-', label=u'Prediction')\n",
    "plt.fill(np.concatenate([x, x[::-1]]),\n",
    "        np.concatenate([y_pred - 1.96 * sigma,\n",
    "                       (y_pred + 1.96 * sigma)[::-1]]),\n",
    "        alpha=.5, fc='b', ec='None', label='95% confidence interval')\n",
    "pass"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
